{"version":3,"file":"js/172.459cb666.js","mappings":"wJAAA,IAAIA,EAAS,WAAkB,IAAIC,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAAEF,EAAII,YAAaF,EAAG,SAAS,CAACG,GAAG,CAAC,MAAQL,EAAIM,mBAAmB,CAACN,EAAIO,GAAG,YAAYP,EAAIQ,KAAMR,EAAII,YAAaF,EAAG,SAAS,CAACG,GAAG,CAAC,MAAQL,EAAIS,kBAAkB,CAACT,EAAIO,GAAG,YAAYP,EAAIQ,KAAMR,EAAII,YAAaF,EAAG,IAAI,CAACF,EAAIO,GAAG,QAAQP,EAAIU,GAAGV,EAAIW,WAAWT,EAAG,IAAI,CAACF,EAAIO,GAAG,mBACxV,EACIK,EAAkB,GCQtB,GACAC,KAAA,OACAC,IAAAA,GACA,OACAC,YAAA,KACAJ,OAAA,GACAP,aAAA,EAEA,EACAY,OAAAA,GACA,4BAAAC,QACA,KAAAF,YAAA,IAAAE,OAAAC,mBAAAC,yBACA,KAAAJ,YAAAK,YAAA,EACA,KAAAL,YAAAM,gBAAA,EACA,KAAAN,YAAAO,KAAA,QACA,KAAAlB,aAAA,GAEAmB,QAAAC,IAAA,aAEA,EACAC,QAAA,CACAnB,gBAAAA,GACA,KAAAF,aAAA,KAAAW,aACA,KAAAA,YAAAW,QACA,KAAAX,YAAAY,SAAAC,IACA,IAAAC,EAAAD,EAAAE,QAAAC,OAAA,EACAC,EAAAJ,EAAAE,QAAAD,GAAA,GAAAI,WACA,KAAAtB,OAAAqB,CAAA,EAEA,KAAAjB,YAAAmB,QAAAN,IAEA,OADAL,QAAAY,MAAA,SAAAP,EAAAO,OACAP,EAAAO,OACA,cACAZ,QAAAC,IAAA,QACA,MACA,kBACAD,QAAAC,IAAA,QACA,MACA,gBACAD,QAAAC,IAAA,WACA,MACA,oBACAD,QAAAC,IAAA,UACA,MACA,YACAD,QAAAC,IAAA,YACA,MACA,QACAD,QAAAC,IAAA,QACA,EAEA,KAAAT,YAAAqB,MAAA,KACAb,QAAAC,IAAA,YAGAD,QAAAC,IAAA,kBAEA,EACAf,eAAAA,GACA,KAAAL,aAAA,KAAAW,aACA,KAAAA,YAAAsB,MAEA,ICxEmP,I,UCO/OC,GAAY,OACd,EACAvC,EACAa,GACA,EACA,KACA,KACA,MAIF,EAAe0B,EAAiB,O","sources":["webpack://ai_bot/./src/components/rdio.vue","webpack://ai_bot/src/components/rdio.vue","webpack://ai_bot/./src/components/rdio.vue?bce7","webpack://ai_bot/./src/components/rdio.vue?9f68"],"sourcesContent":["var render = function render(){var _vm=this,_c=_vm._self._c;return _c('div',[(_vm.isSupported)?_c('button',{on:{\"click\":_vm.startRecognition}},[_vm._v(\"开始语音输入\")]):_vm._e(),(_vm.isSupported)?_c('button',{on:{\"click\":_vm.stopRecognition}},[_vm._v(\"停止语音输入\")]):_vm._e(),(_vm.isSupported)?_c('p',[_vm._v(\"识别结果：\"+_vm._s(_vm.result))]):_c('p',[_vm._v(\"当前浏览器不支持语音识别\")])])\n}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","<template>\r\n  <div>\r\n    <button v-if=\"isSupported\" @click=\"startRecognition\">开始语音输入</button>\r\n    <button v-if=\"isSupported\" @click=\"stopRecognition\">停止语音输入</button>\r\n    <p v-if=\"isSupported\">识别结果：{{ result }}</p>\r\n    <p v-else>当前浏览器不支持语音识别</p>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nexport default {\r\n  name:'Rdio',\r\n  data() {\r\n    return {\r\n      recognition: null,\r\n      result: '',\r\n      isSupported: false\r\n    };\r\n  },\r\n  mounted() {\r\n    if ('webkitSpeechRecognition' in window) {\r\n      this.recognition = new (window.SpeechRecognition || webkitSpeechRecognition)();\r\n      this.recognition.continuous = true;\r\n      this.recognition.interimResults = true;\r\n      this.recognition.lang = 'zh-CN'; // 设置识别语言\r\n      this.isSupported = true;\r\n    } else {\r\n      console.log('浏览器不支持语音识别');\r\n    }\r\n  },\r\n  methods: {\r\n    startRecognition() {\r\n      if (this.isSupported && this.recognition) {\r\n        this.recognition.start();\r\n        this.recognition.onresult = event => {\r\n          let last = event.results.length - 1;\r\n          let text = event.results[last][0].transcript;\r\n          this.result = text;\r\n        };\r\n        this.recognition.onerror = event => {\r\n          console.error('语音识别错误', event.error);\r\n          switch (event.error) {\r\n            case 'network':\r\n              console.log('网络错误');\r\n              break;\r\n            case 'not-allowed':\r\n              console.log('没有权限');\r\n              break;\r\n            case 'no-speech':\r\n              console.log('没有检测到语音');\r\n              break;\r\n            case 'audio-capture':\r\n              console.log('音频捕获失败');\r\n              break;\r\n            case 'start':\r\n              console.log('语音识别启动失败');\r\n              break;\r\n            default:\r\n              console.log('未知错误');\r\n          }\r\n        };\r\n        this.recognition.onend = () => {\r\n          console.log('语音识别结束');\r\n        };\r\n      } else {\r\n        console.log('语音识别未初始化或浏览器不支持');\r\n      }\r\n    },\r\n    stopRecognition() {\r\n      if (this.isSupported && this.recognition) {\r\n        this.recognition.stop();\r\n      }\r\n    }\r\n  }\r\n};\r\n</script>\r\n\r\n<style>\r\n</style>","import mod from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./rdio.vue?vue&type=script&lang=js\"; export default mod; export * from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./rdio.vue?vue&type=script&lang=js\"","import { render, staticRenderFns } from \"./rdio.vue?vue&type=template&id=1b7f7b21\"\nimport script from \"./rdio.vue?vue&type=script&lang=js\"\nexport * from \"./rdio.vue?vue&type=script&lang=js\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports"],"names":["render","_vm","this","_c","_self","isSupported","on","startRecognition","_v","_e","stopRecognition","_s","result","staticRenderFns","name","data","recognition","mounted","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","console","log","methods","start","onresult","event","last","results","length","text","transcript","onerror","error","onend","stop","component"],"sourceRoot":""}